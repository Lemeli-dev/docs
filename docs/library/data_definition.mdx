---
title: 'Data definition'
description: 'How to map the input data.'
noindex: true
---

To run evaluations, you must create a `Dataset` object with a `DataDefinition`, which maps:

* **Column types** (e.g., categorical, numerical, text, embeddings).

* **Column roles** (e.g., prediction, target, LLM output, etc.).

This helps Evidently process the data correctly. Some evaluations require certain columns, and will fail if these are missing.

You can create a `DataDefinition` in Python before generating a Report or map the columns visually in the Evidently platform. **Automated data definition** is also available in some cases.

<Info>
  Check data requirements for specific Metrics in the [Reference table](/metrics/all_metrics).
</Info>

## Basic flow

**Import** the following modules:

```python
from evidently.future.datasets import Dataset
from evidently.future.datasets import DataDefinition
```

**Create a Dataset**. You can pass data with [flexible structure](/docs/library/overview#dataset).

* Prepare it as a pandas.DataFrame.

* Create an Evidently Dataset object using `Dataset.from_pandas`.

* Pass the corresponding `data_definition`. For automated mapping, pass an empty `DataDefinition()`object:

```python
eval_data = Dataset.from_pandas(
    pd.DataFrame(source_df),
    data_definition=DataDefinition()
)
```

**Two datasets.** If you're using two datasets (like current and reference for drift detection), create a Dataset object for each. They must have identical data definition.

**Automated data definition.**  If the data definition is not specified, Evidently tries to map columns:

* Based on type (numerical, categorical).

* By matching column names to known roles (e.g., a column "target" treated as the target).

**Manual data definition.** While automation works in many cases, manual mapping is more accurate. It helps avoid mistakes like misclassifying numerical columns with few unique values as categorical. Some evaluations, like text or embedding drift detection require explicit mapping.

<Info>
  Once you have the **Dataset** ready, you can add [text Descriptors ](/docs/library/descriptors)and/or [get Reports](/docs/library/report).
</Info>

You can explore different mapping options below. Note that you only need to use those relevant to your evals. For example, you don’t need roles like target/prediction to run data quality checks.

## Column types

**Why map column types**. This ensures accurate data processing for:

* Statistical analysis. Descriptive stats adjust based on column type.

* Choice of visualizations. This also prevents unsuitable plots (e.g., text columns treated as categorical may get a raw text distribution histogram).

* Data drift analysis. Drift detection methods vary by column type.

* Automated tests choice. Preset composition is mapped to column types.

<Note>
  If you have **text data**, you can [generate descriptors](/docs/library/descriptors) without explicit mapping. However, mapping is recommended since you may later generate dataset-level Reports, like to get a Data Summary.
</Note>

### Examples

**Tabular or text data**. Example mapping:

```python
definition = DataDefinition(
    text_columns=["Latest_Review"],
    numerical_columns=["Age", "Salary"],
    categorical_columns=["Department"],
    datetime_columns=["Joining_Date"]
    )
    
eval_data = Dataset.from_pandas(
    pd.DataFrame(source_df),
    data_definition=definition
)
```

(TBC). **Embeddings** Example mapping:

```python
embeddings = {'small_subset': embeddings_data.columns[:10]} #TBC
```

<Info>
  If you map column types and exclude certain columns, they’ll be ignored in all evaluations.
</Info>

### Options

Available types and how automated mapping works.

| **Column Type**       | **Description**                                                                                                                                                                                         | **Automated Mapping**                               |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| `numerical_columns`   | <ul><li>Columns with numeric values.</li></ul>                                                                                                                                                          | All columns with numeric types (`np.number`).       |
| `datetime_columns`    | <ul><li>Columns with datetime values.</li><li>Ignored in data drift calculations.</li></ul>                                                                                                             | All columns with DateTime format (`np.datetime64`). |
| `categorical_columns` | <ul><li>Columns with categorical values.</li></ul>                                                                                                                                                      | All non-numeric/non-datetime columns.               |
| `text_columns`        | <ul><li>Text columns.</li><li>Mapping **required** for text data drift detection.</li></ul>                                                                                                             | No automated mapping.                               |
| `embeddings` (TBC)    | <ul><li>Columns containing embeddings.</li><li> Pass a dictionary where keys are embedding names and values are lists of columns.</li><li>Mapping **required** for embedding drift detection.</li></ul> | No automated mapping.                               |

## Column roles

Depending on the use case and type of analysis to run, you may need to map specific column roles.

### General

If you have a timestamp or ID column, it's always a good idea to identify them.

| **Column role** | **Description**                                                                                      | **Automated mapping**          |
| --------------- | ---------------------------------------------------------------------------------------------------- | ------------------------------ |
| `id_column`     | <ul><li>Identifier column.</li><li>Ignored in data drift calculations.</li></ul>                     | Column named "id" (TBC)        |
| `timestamp`     | <ul><li>Timestamp column.</li><li> Ignored in data drift calculations (like any DateTime).</li></ul> | Column named "timestamp" (TBC) |

<Info>
  How is`timestamp` different from `datetime_columns`?

  * **DateTime** is a column type. You can have many DateTime columns in the dataset. For example, conversation start / end time or features like "date of last contact."

  * **Timestamp** is a role. You can have a single timestamp column. It often represents the time when a data input was recorded. Use it if you want to see it as index on the plots.
</Info>

### LLM evals

When you generate [text descriptors](/docs/library/descriptors) and add them to the dataset, they are automatically mapped as `descriptors` in Data Definition. This means they will be included in the `TextEvals` [preset](/metrics/preset_text_evals) or treated as descriptor when you plot them on the dashboard.

However, if you computed some scores or metadata and want to treat them as decriptors, you can map them manually.

```python
definition = DataDefinition(
    numerical_descriptors=["chat_length", "user_rating"],
    categorical_descriptors=["upvotes", "model_type"]
    )
```

### Regression

To run regression quality checks, you must map the columns with:
* Target: actual values.
* Prediction: predicted values.

You can have several regression results in the dataset, for example in case of multiple regression. (Pass the mappings in a list).

Example mapping:

```python
definition = DataDefinition(
    regression: [Regression()]
    )
```

Defaults:

```python
    target: str = "target"
    prediction: str = "prediction"
```    

### Classification

To run classification checks, you must map the columns with:
* Target: true label.
* Prediction: predicted labels/probabilities.

There two different mapping options, for binary and multi-class classification. You can also have several classification results in the dataset. (Pass the mappings in a list). 

#### Multiclass

Example mapping:

```python
definition = DataDefinition(
    classification=[MulticlassClassification()]
    )
```

Available options and defaults:

```python
    target: str = "target"
    prediction_labels: str = "prediction"
    prediction_probas: Optional[List[str]] = None #if probabilistic classification
    labels: Optional[Dict[Label, str]] = None
```

#### Binary

Example mapping:

```python
definition = DataDefinition(
    classification=[BinaryClassification()]
    )
```

Available options and defaults:

```python
    target: str = "target"
    prediction_labels: Optional[str] = None
    prediction_probas: Optional[str] = "prediction" #if probabilistic classification
    pos_label: Label = 1 #name of the positive label
    labels: Optional[Dict[Label, str]] = None
```

### Ranking

#### RecSys 

To evaluate recommender systems performance, you must map the columns with:
* Prediction: this could be predicted score or rank.
* Target: relevance labels (e.g., this could be an interaction result like user click or upvote, or a true relevance label)

The **target** column can contain either:
* a binary label (where `1` is a positive outcome)
* any true labels or scores (any positive values, where a higher value corresponds to a better match or a more valuable user action).

Here are the examples of the expected data inputs.

If the system prediction is a **score** (expected by default):

| user_id | item_id | prediction (score) | target (relevance) |
| -------- | -------- | ------------------ | ------------------ |
| user_1  | item_1  | 1.95               | 0                  |
| user_1  | item_2  | 0.8                | 1                  |
| user_1  | item_3  | 0.05               | 0                  |

If the model prediction is a **rank**:

| user_id | item_id | prediction (rank) | target (relevance) |
| -------- | -------- | ----------------- | ------------------ |
| user_1  | item_1  | 1                 | 0                  |
| user_1  | item_2  | 2                 | 1                  |
| user_1  | item_3  | 3                 | 0                  |


Example mapping:

```python
definition = DataDefinition(
    ranking=[Recsys()]
    )
```
Available options and defaults:

```python
    user_id: str = "user_id" #columns with user IDs
    item_id: str = "item_id" #columns with ranked items
    target: str = "target"
    prediction: str = "prediction"
``
    
TBC
* `recommendations_type`: `score` (default) or `rank`. Helps specify whether the prediction column contains ranking or predicted score.