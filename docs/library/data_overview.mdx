---
title: 'Overview'
description: 'How to prepare input data to run evaluations.'
---

## Data structure

**Tabular format**. To run an evaluation, you must prepare your data in tabular format as a pandas DataFrame. All column names must be strings.

**Flexible structure**. The table can include any combination of numerical, categorical, text, metadata (including timestamps or IDs), and embeddings columns.

Here are a few examples.

<Tabs>
  <Tab title="LLM logs">
    To evaluate generative AI quality, pass LLM outputs with optional context and ground truth. You can inlcude any number of text and metadata columns.

    | Question                             | Context                                                                                                   | Answer                          |
    | ------------------------------------ | --------------------------------------------------------------------------------------------------------- | ------------------------------- |
    | How old is the universe?             | The universe is believed to have originated from the Big Bang that occurred 13.8 billion years ago.       | 13.8 billion years old.         |
    | What’s the lifespan of Baobab trees? | Baobab trees can live up to 2,500 years. They are often called the “Tree of Life”.                        | Up to 2,500 years.              |
    | What is the speed of light?          | The speed of light in a vacuum is approximately 299,792 kilometers per second (186,282 miles per second). | Close to 299,792 km per second. |
  </Tab>

  <Tab title="Data table">
    Pass any data table to get a data overview, run data quality and distribution drift checks. This could also be production logs of your ML model with input features and prediction column.

    | Order ID | Product                | Category    | Quantity | Price  | Payment Method | Shipping Status |
    | -------- | ---------------------- | ----------- | -------- | ------ | -------------- | --------------- |
    | ORD001   | Wireless Headphones    | Electronics | 1        | 120.00 | Credit Card    | Shipped         |
    | ORD002   | Yoga Mat               | Sports      | 2        | 45.00  | PayPal         | In Transit      |
    | ORD003   | Stainless Steel Bottle | Kitchen     | 3        | 30.00  | Debit Card     | Delivered       |
  </Tab>

  <Tab title="Classification">
    To evaluate classification quality, pass a table that contains columns with predicted and actual label. Features are optional, but useful for some evals.

    | Timestamp           | Transaction ID | Amount  | Location      | Device Type | Fraud Label | Target |
    | ------------------- | -------------- | ------- | ------------- | ----------- | ----------- | ------ |
    | 2023-12-01 10:15:23 | TXN001         | 250.00  | New York, USA | Mobile      | 0           | 0      |
    | 2023-12-01 10:17:45 | TXN002         | 5000.00 | London, UK    | Desktop     | 1           | 1      |
    | 2023-12-01 10:20:10 | TXN003         | 1200.00 | Sydney, AUS   | Tablet      | 0           | 0      |
  </Tab>

  <Tab title="Regression">
    To evaluate regression quality, pass a table that contains columns with predicted and actual values. Input features are optional.

    | Prop ID | Location      | Sq ft | Type      | Bedrooms | Has Garden | Predicted  ($) | Actual ($) |
    | ------- | ------------- | ----- | --------- | -------- | ---------- | -------------- | ---------- |
    | P01     | New York, USA | 850   | Apartment | 2        | No         | 850,000        | 870,000    |
    | P02     | New York, USA | 1200  | House     | 3        | Yes        | 1,250,000      | 1,300,000  |
    | P03     | London, UK    | 950   | Flat      | 2        | No         | 700,000        | 720,000    |
  </Tab>

  <Tab title="Ranking">
    To evaluate ranking or recommendations, pass a table that contains columns with rank/score and interaction result. User/query and item features are optional but useful for some evals.

    | User ID | Movie ID | Movie Title  | Genre         | Average Viewer Rating | Watched Duration (%) | Predicted Rank |
    | ------- | -------- | ------------ | ------------- | --------------------- | -------------------- | -------------- |
    | U001    | M001     | The Matrix   | Sci-Fi        | 4.8                   | 100                  | 1              |
    | U002    | M002     | Titanic      | Romance/Drama | 4.5                   | 80                   | 2              |
    | U001    | M003     | Interstellar | Sci-Fi        | 4.7                   | 90                   | 2              |
  </Tab>

  <Tab title="Embeddings">
    To evaluate embeddings drift, pass embeddings as numerical columns.

    | User ID | Movie ID | Title  | Genre         | Avg Rating | Watched (%) | Predicted Rank |
    | ------- | -------- | ------------ | ------------- | --------------------- | -------------------- | -------------- |
    | U001    | M001     | The Matrix   | Sci-Fi        | 4.8                   | 100                  | 1              |
    | U002    | M002     | Titanic      | Romance/Drama | 4.5                   | 80                   | 2              |
    | U001    | M003     | Interstellar | Sci-Fi        | 4.7                   | 90                   | 2              |
  </Tab>
</Tabs>

## Column Mapping

Some evaluations require specific columns or data types present.

For example, to evaluate classification quality, you need both predicted labels (prediction) and actual labels (target) columns. To specify where they are located in your table, you can map the data schema using the Column Mapping object.

## Two Datasets

By default, evaluations use a single dataset (`current` dataset). Optionally, you can include a second dataset (`reference` dataset). Both datasets must have identical structures.

When to use two datasets:

* **Side-by-side comparison**. Compare outputs or data quality across two periods or model versions in a single Report.

* **Data drift detection**. Detect distribution shifts by comparing datasets, such as this week’s data to the previous one. (Reference dataset is required).

* **Simplify test setup**. Automatically generate test conditions (e.g., min-max ranges) from the reference dataset without manual configuration.

## Data sampling

Running evaluations on large datasets (millions of rows) can take time. This depends on the specific evaluation as well as your infrastructure. Since pandas processes data in memory, it’s often more efficient to use samples.

For example, in data drift detection, you can apply random or stratified sampling and compare samples instead of processing the entire dataset.