---
title: "All Metrics"
description: "Reference page for all Metrics."
noindex: "true"
---

You can use **Metrics** and **Presets** to:

* evaluate raw data or computed text descriptors (descriptive stats, quality, drift)

* evaluate AI system performance (LLM, regression, classification, ranking, etc.)

Each Metric includes a default visual. Learn more in [Key Concepts](/docs/library/overview).

<Accordion title="How to read the tables" defaultOpen={false}>
  * **Metric**: the name of Metric or Preset you can pass to `Report`.

  * **Description:** what it does. Complex Metrics link to explainer pages.

  * **Parameters:** available options. You can also add conditional `tests` to any Metric with standard operators like `eq` (equal), `gt` (greater than), etc. [How Tests work](/docs/library/tests).

  * **Test defaults** are conditions that apply when you invoke Tests but do not set a pass/fail condition yourself.

    * **With reference**: if you provide a reference dataset during the Report `run`, the conditions are set relative to reference.

    * **No reference**: if you do not provide a reference, Tests will use fixed heuristics (like expect no missing values).
</Accordion>

## Text Evals

Use to summarize results of output-level text or LLM evals.

| Metric          | Description                                                                                                                                                                                                                                                                                             | Parameters | Test Defaults |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- | ------------- |
| **TextEvals()** | <ul><li>Large Preset.</li><li>Shows `ValueStats` for all descriptors.</li><li>You must specify descriptors ([see how](/docs/library/descriptors) and [all descriptors](/metrics/all_descriptors)).</li><li>Metric result: for all Metrics.</li><li>[Preset page](/metrics/preset/text_evals).</li></ul> | TBC        | TBC           |

## Columns

Use to aggregate descriptor results or check data quality on column level.&#x20;

### Value stats

Descriptive statistics.

| Metric                                                                                                         | Description                                                                                                                                                                                                                                 | Parameters                                                                                                                                        | Test Defaults                                                                                                                        |
| -------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| **ValueStats()**                                                                                               | <ul><li>Small Preset, column-level. </li><li>Computes various descriptive stats (min, max, mean, quantiles, most common, etc.)</li><li>Returns different stats based on the column type (text, categorical, numerical, datetime).</li></ul> | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                   | <ul><li>**No reference**. TBC.</li><li>**With reference**. As in indiviudal Metrics.</li></ul>                                       |
| **MinValue()**                                                                                                 | <ul><li>Column-level.</li><li>Returns min value for a given numerical column.</li><li>Metric result: `min`.</li></ul>                                                                                                                       | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                   | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if Min Value is differs by more than 10% (+/-).</li></ul>           |
| **StdValue()**                                                                                                 | <ul><li>Column-level.</li><li>Computes the standard deviation of a given numerical column.</li><li>Metric result: `std`.</li></ul>                                                                                                          | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                   | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if the standard deviation differs by more than 10% (+/-).</li></ul> |
| **MeanValue()**                                                                                                | <ul><li>Column-level.</li><li>Computes the mean value of a given numerical column.</li><li>Metric result: `mean`.</li></ul>                                                                                                                 | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                   | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if the mean value differs by more than 10%.</li></ul>               |
| **MaxValue()**                                                                                                 | <ul><li>Column-level.</li><li>Computes the max value of a given numerical column.</li><li>Metric result: `max`.</li></ul>                                                                                                                   | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                   | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if the max value is higher than in the reference.</li></ul>         |
| **MedianValue()**                                                                                              | <ul><li>Column-level.</li><li>Computes the median value of a given numerical column.</li><li>Metric result: `median`.</li></ul>                                                                                                             | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                   | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if the median value differs by more than 10% (+/-).</li></ul>       |
| **QuantileValue()**                                                                                            | <ul><li>Column-level.</li><li>Computes the quantile value of a given numerical column.</li><li>Defaults to 0.5 if no quantile is specified.</li><li>Metric result: `quantile`.</li></ul>                                                    | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>`quantile` (default: 0.5)</li><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if quantile value differs by more than 10% (+/-).</li></ul>         |
| **CategoryCount()** <br /><br /> Example: <br /> `CategoryCount(`<br />`column="city",`<br />` category="NY")` | <ul><li>Column-level.</li><li>Counts occurrences of the specified category.</li><li>Metric result: `count`, `share`.</li></ul>                                                                                                              | **Required**: <ul><li>`column`</li><li>`category`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                | <ul><li>**No reference**. N/A.</li><li>**With reference**. Fails if the specified category is not present.</li></ul>                 |

### Column data quality

Column-level data quality metrics.

| Metric                                                                                                                         | Description                                                                                                                                                        | Parameters                                                                                                                                     | Test Defaults                                                                                                                                                      |
| ------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **MissingValueCount()**                                                                                                        | <ul><li>Column-level.</li><li>Counts the number and share of missing values.</li><li>Metric result: `count`, `share`.</li></ul>                                    | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                | <ul><li>**No reference**: Fails if there are missing values.</li><li>**With reference**: Fails if share of missing values is >10% higher.</li></ul>                |
| **NewCategoriesCount()**                                                                                                       | <ul><li>Column-level.</li><li>Counts new categories compared to reference (reference required).</li><li>Metric result: TBC.</li></ul>                              | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                | TBC                                                                                                                                                                |
| **MissingCategoriesCount()**                                                                                                   | <ul><li>Column-level.</li><li>Counts missing categories compared to reference.</li><li>Metric result: TBC.</li></ul>                                               | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                | TBC                                                                                                                                                                |
| **InRangeValueCount()**  <br /><br /> Example: <br /> `InRangeValueCount(`<br />`column="age",`<br />`left="1", right="18")`   | <ul><li>Column-level.</li><li>Counts the number and share of values in the set range.</li><li>Metric result: `count`, `share`.</li></ul>                           | **Required**: <ul><li>`column`</li><li>`left`</li><li>`right`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: N/A.</li><li>**With reference**: Fails if column contains values out of the min-max reference range.</li></ul>                           |
| **OutRangeValueCount()**                                                                                                       | <ul><li>Column-level.</li><li>Counts the number and share of values out of the set range.</li><li>Metric result: `count`, `share`.</li></ul>                       | **Required**: <ul><li>`column`</li><li>`left`</li><li>`right`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: N/A.</li><li>**With reference**: Fails if any value is out of min-max reference range.</li></ul>                                         |
| **InListValueCount()**                                                                                                         | <ul><li>Column-level.</li><li>Counts the number and share of values in the set list.</li><li>Metric result: `count`, `share`.</li></ul>                            | **Required**: <ul><li>`column`</li><li>`values`</li></ul>**Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                | <ul><li>**No reference**: N/A.</li><li>**With reference**: Fails if any value is out of list.</li></ul>                                                            |
| **OutListValueCount()**  <br /><br /> Example: <br /> `OutListValueCount(`<br />`column="city",`<br />` values=["Lon", "NY"])` | <ul><li>Column-level.</li><li>Counts the number and share of values out of the set list.</li><li>Metric result: `count`, `share`.</li></ul>                        | **Required**: <ul><li>`column`</li><li>`values`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>               | <ul><li>**No reference**: N/A.</li><li>**With reference**: Fails if any value is out of list.</li></ul>                                                            |
| **UniqueValueCount()**                                                                                                         | <ul><li>Column-level.</li><li>Counts the number and share of unique values.</li><li>Metric result (dict): `count`, `share` for `value`.</li></ul>                  | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                | <ul><li>**No reference**: TBC.</li><li>**With reference**: Fails if the share of unique values differs by >10% (+/-).</li></ul>                                    |
| **MostCommonValueCount()**                                                                                                     | <ul><li>Column-level.</li><li>Identifies the most common value and provides its count/share.</li><li>Metric result (dict): `count`, `share` for `value`.</li></ul> | **Required**: <ul><li>`column`</li></ul> **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                | <ul><li>**No reference**: Fails if most common value share is ≥80%.</li><li>**With reference**:  Fails if most common value share differs by >10% (+/-).</li></ul> |

## Dataset

Use for exploratory data analysis and data quality checks.

### Dataset stats

Descriptive statistics.

| Metric                  | Description                                                                                                                                                                                                         | Parameters                                                             | Test Defaults                                                                                                                                   |
| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| **DataSummaryPreset()** | <ul><li>Large Preset.</li><li>Combines `DatasetStats` and `ValueStats` for all or specified columns.</li><li>Metric result: for all Metrics.</li><li>[Preset page](/metrics/preset_data_summary)</li></ul>          | **Optional**: <ul><li>`columns`</li></ul>                              | As in individual Metrics.                                                                                                                       |
| **DatasetStats()**      | <ul><li>Small preset. </li><li> Dataset-level.</li><li>Calculates descriptive dataset stats, including columns by type, rows, missing values, empty columns, etc.</li><li>Metric result: for all Metrics.</li></ul> | TBC                                                                    | <ul><li>**No reference**: TBC.</li><li>**With reference**: Same as for Metrics in Preset.</li></ul>                                             |
| **RowCount()**          | <ul><li> Dataset-level.</li><li>Counts the number of rows.</li><li>Metric result: TBC.</li></ul>                                                                                                                    | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: Fails if the number of rows is 30 or under.</li><li>**With reference**: Fails if row count differs by >10%.</li></ul> |
| **ColumnCount()**       | <ul><li> Dataset-level.</li><li>Counts the number of columns.</li><li>Metric result: TBC.</li></ul>                                                                                                                 | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul> | TBC                                                                                                                                             |

### Dataset data quality

Dataset-level data quality metrics.

| Metric                              | Description                                                                                                                                                                        | Parameters                                                                                                      | Test Defaults                                                                                                                                                 |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **ConstantColumnCount()**           | <ul><li> Dataset-level.</li><li>Counts the number of constant columns.</li><li>Metric result: TBC.</li></ul>                                                                       | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | <ul><li>**No reference**: Fails if there is at least one constant column.</li><li>**With reference**: Fails if count is higher than in reference.</li></ul>   |
| **EmptyRowCount()**                 | <ul><li> Dataset-level.</li><li>Counts the number of empty rows.</li><li>Metric result: TBC.</li></ul>                                                                             | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | <ul><li>**No reference**: Fails if there is at least one empty row.</li><li>**With reference**: Fails if share differs by >10%.</li></ul>                     |
| **EmptyColumnCount()**              | <ul><li> Dataset-level.</li><li>Counts the number of empty columns.</li><li>Metric result: TBC.</li></ul>                                                                          | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | <ul><li>**No reference**: Fails if there is at least one empty column.</li><li>**With reference**: Fails if count is higher than in reference.</li></ul>      |
| **DuplicatedRowCount()**            | <ul><li> Dataset-level.</li><li>Counts the number of duplicated rows.</li><li>Metric result: TBC.</li></ul>                                                                        | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | <ul><li>**No reference**: Fails if there is at least one duplicated row.</li><li>**With reference**: Fails if share differs by >10% (+/-).</li></ul>          |
| **DuplicatedColumnCount()**         | <ul><li> Dataset-level.</li><li>Counts the number of duplicated columns.</li><li>Metric result: TBC.</li></ul>                                                                     | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | <ul><li>**No reference**: Fails if there is at least one duplicated column.</li><li>**With reference**: Fails if count is higher than in reference.</li></ul> |
| **DatasetMissingValueCount()**      | <ul><li> Dataset-level.</li><li>Calculates the number and share of missing values.</li><li>Displays the number of missing values per column.</li><li>Metric result: TBC.</li></ul> | **Required**: <ul><li>`columns`</li></ul>**Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: Fails if there are missing values.</li><li>**With reference**: Fails if share is >10% higher than reference (+/-).</li></ul>        |
| **AlmostEmptyColumnCount()**        | <ul><li> Dataset-level.</li><li>Counts almost empty columns (95% empty).</li><li>Metric result: TBC.</li></ul>                                                                     | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | TBC                                                                                                                                                           |
| **AlmostConstantColumnCount()**     | <ul><li> Dataset-level.</li><li>Counts almost constant columns (95% identical values).</li><li>Metric result: TBC.</li></ul>                                                       | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | TBC                                                                                                                                                           |
| **RowsWithMissingValuesCount()**    | <ul><li> Dataset-level.</li><li>Counts rows with missing values.</li><li>Metric result: TBC.</li></ul>                                                                             | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | TBC                                                                                                                                                           |
| **ColumnsWithMissingValuesCount()** | <ul><li> Dataset-level.</li><li>Counts columns with missing values.</li><li>Metric result: TBC.</li></ul>                                                                          | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                          | TBC                                                                                                                                                           |

## Data Drift

Use to detect distribution drift for text, tabular, embeddings data or over computed text descriptors. 20+ drift methods listed separately: [text and tabular](/metrics/customize_data_drift), [embeddings](/metrics/customize_embedding_drift).

| Metric                    | Description                                                                                                                                                                                                                                                                                                                                | Parameters                                                                                                                                                                                                                                                                             | Test Defaults                                                                                                                            |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **DataDriftPreset()**     | <ul><li>Large Preset. </li><li> Requires reference.</li><li>Calculates data drift for all or set columns. </li><li> Uses the default or set method.</li><li>Returns drift score for each column.</li><li>Visualizes all distributions.</li><li>Metric result: all Metrics.</li><li>[Preset page](/metrics/customize_data_drift).</li></ul> | **Optional**: <ul><li>`columns`</li><li>`method`</li><li>`cat_method`</li><li>`num_method`</li><li>`per_column_method`</li><li>`threshold`</li><li>`cat_threshold`</li><li>`num_threshold`</li><li>`per_column_threshold`</li></ul>See [drift options](/metrics/customize_data_drift). | <ul><li>**With reference**: Data drift defaults, depending on column type. See [drift methods](/metrics/customize_data_drift).</li></ul> |
| **DriftedColumnsCount()** | <ul><li> Dataset-level. </li><li> Requires reference.</li><li>Calculates the number and share of drifted columns in the dataset.</li><li>Each column is tested for drift using the default algorithm or set method.</li><li>Returns only the total number of drifted columns.</li><li>Metric result: TBC.</li></ul>                        | **Optional**: <ul><li>`columns`</li><li>`method`</li><li>`cat_method`</li><li>`num_method`</li><li>`per_column_method`</li><li>`threshold`</li><li>`cat_threshold`</li><li>`num_threshold`</li><li>`per_column_threshold`</li></ul>See [drift options](/metrics/customize_data_drift). | <ul><li>**With reference**: Fails if 50% of columns are drifted.</li></ul>                                                               |
| **ValueDrift()**          | <ul><li>Column-level.</li><li> Requires reference.</li><li>Calculates data drift for a defined column (num, cat, text).</li><li>Visualizes distributions.</li><li>Metric result: TBC.</li></ul>                                                                                                                                            | **Required**: <ul><li>`column`</li></ul>**Optional:** <ul><li>`method`</li><li>`threshold`</li></ul>See [drift options](/metrics/customize_data_drift).                                                                                                                                | <ul><li>**With reference**: Data drift defaults, depending on column type. See [drift methods](/metrics/customize_data_drift).</li></ul> |
| **MultivariateDrift()**   | <ul><li>Dataset-level.</li><li> Requires reference.</li><li>Computes a single dataset drift score.</li><li>Default method: TBC.</li><li>Metric result: TBC.</li></ul>                                                                                                                                                                      | **Optional**: <ul><li>`columns`</li><li>`method`</li></ul>See [drift options](/metrics/customize_data_drift).                                                                                                                                                                          | <ul><li>**With reference**: Defaults for method. See [methods](/metrics/customize_data_drift).             </li></ul>                    |
| **EmbeddingDrift()**      | <ul><li>Column-level.</li><li> Requires reference.</li><li>Calculates data drift for embeddings.</li><li>Requires embedding columns set in data definition.</li></ul>                                                                                                                                                                      | **Required**: <ul><li>`embeddings`</li><li>`method`</li></ul> See [embedding drift options](/metrics/customize_embedding_drift).                                                                                                                                                       | <ul><li>**With reference**: Defaults for method. See [methods](/metrics/customize_embedding_drift).</li></ul>                            |

## Correlations

Use for exploratory data analysis, drift monitoring (correlation changes) or to check alignment between scores (e.g. LLM-based descriptors against human labels).

| Metric                    | Description                                                                                                                                                                                                                           | Parameters                                                                                                                                                                                                                        | Test Defaults                                                                                  |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| **DatasetCorrelations()** | <ul><li>Calculates the correlations between all or set columns in the dataset.</li><li>Supported methods: Pearson, Spearman, Kendall, Cramer\_V.</li><li>Metric result: TBC.</li></ul>                                                | **Optional**: <ul><li>`columns`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                                                                          | TBC                                                                                            |
| **Correlation()**         | <ul><li>Calculates the correlation between two defined columns.</li><li>Metric result: TBC.</li></ul>                                                                                                                                 | **Required**: <ul><li>`column_x`</li><li>`column_y`</li></ul>**Optional**:<ul><li>`method` (default: `pearson`, available: `pearson`, `spearman`, `kendall`, `cramer_v`)</li><li>[Test conditions](/docs/library/tests)</li></ul> | TBC                                                                                            |
| **CorrelationChanges()**  | <ul><li>Dataset-level.</li><li>Reference required.</li><li>Checks the number of correlation violations (significant changes in correlation strength between columns) across all or set columns.</li><li>Metric result: TBC.</li></ul> | **Optional**: <ul><li>`columns`</li><li>`method` (default: `pearson`, available: `pearson`, `spearman`, `kendall`, `cramer_v`)</li><li>`corr_diff` (default: 0.25)</li><li>[Test conditions](/docs/library/tests)</li></ul>       | <ul><li>**With reference**: Fails if at least one correlation violation is detected.</li></ul> |

## Classification

Use to evaluate quality on a classification task (probabilistic, non-probabilistic, binary and multi-class). You must map predictions and target columns using [data definition](/docs/library/data_definition).

### General

Use for binary classification and aggregated results for multi-class.

| Metric                      | Description                                                                                                                                                                 | Parameters                                                                                                                                                                                                                        | Test Defaults                                                                                                                                                                        |
| --------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **ClassificationPreset()**  | <ul><li>Large Preset with many classification Metrics and visuals.</li><li>See [Preset page](/metrics/preset_classification).</li><li>Metric result: all Metrics.</li></ul> | None.                                                                                                                                                                                                                             | As in individual Metrics.                                                                                                                                                            |
| **ClassificationQuality()** | <ul><li>Small Preset.</li><li>Summarizes quality Metrics in a single widget.</li><li>Metric result: all Metrics.</li></ul>                                                  | TBC.                                                                                                                                                                                                                              | As in individual Metrics.                                                                                                                                                            |
| **LabelCount()**            | <ul><li>Distribution of predicted classes.</li><li>Can visualize class balance and/or probability distribution.</li><li>Metric result: TBC.</li></ul>                       | **Required**: <ul><li>Set at least one visualization: `class_balance`, `prob_distribution`.</li></ul>  **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                                     | TBC                                                                                                                                                                                  |
| **Accuracy()**              | <ul><li>Calculates accuracy.</li><li>Metric result: TBC.</li></ul>                                                                                                          | **Optional**: <ul><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                                                                                                                                                               | <ul><li>**No reference**: Fails if lower than dummy model accuracy.</li><li>**With reference**: Fails if accuracy differs by >20%.</li></ul>                                         |
| **Precision()**             | <ul><li>Calculates precision.</li><li>Visualizations available: Confusion Matrix, PR Curve, PR Table.</li><li>Metric result: TBC.</li></ul>                                 | **Required**: <ul><li>Set at least one visualization: `conf_matrix`, `pr_curve`, `pr_table`.</li></ul> **Optional**: <ul><li>`probas_threshold` (default: None or 0.5 for probabilistic classification)</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>   | <ul><li>**No reference**: Fails if Precision is lower than the dummy model.</li><li>**With reference**: Fails if Precision differs by >20%.</li></ul>                                |
| **Recall()**                | <ul><li>Calculates recall.</li><li>Visualizations available: Confusion Matrix, PR Curve, PR Table.</li><li>Metric result: TBC.</li></ul>                                    | **Required**: <ul><li>Set at least one visualization: `conf_matrix`, `pr_curve`, `pr_table`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                           | <ul><li>**No reference**: Fails if lower than dummy model recall.</li><li>**With reference**: Fails if Recall differs by >20%.</li></ul>                                             |
| **F1Score()**               | <ul><li>Calculates F1 Score.</li><li>Metric result: TBC.</li></ul>                                                                                                          | **Required**: <ul><li>Set at least one visualization: `conf_matrix`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                   | <ul><li>**No reference**: Fails if lower than dummy model F1.</li><li>**With reference**: Fails if F1 differs by >20%.</li></ul>                                                     |
| **TPR()**                   | <ul><li>Calculates True Positive Rate (TPR).</li><li>Metric result: TBC.</li></ul>                                                                                          | **Required**: <ul><li>Set at least one visualization: `pr_table`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                   | <ul><li>**No reference**: Fails if TPR is lower than the dummy model.</li><li>**With reference**: Fails if TPR differs by >20%.</li></ul>                                            |
| **TNR()**                   | <ul><li>Calculates True Negative Rate (TNR).</li><li>Metric result: TBC.</li></ul>                                                                                          | **Required**: <ul><li>Set at least one visualization: `pr_table`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                    | <ul><li>**No reference**: Fails if TNR is lower than the dummy model.</li><li>**With reference**: Fails if TNR differs by >20%.</li></ul>                                            |
| **FPR()**                   | <ul><li>Calculates False Positive Rate (FPR).</li><li>Metric result: TBC.</li></ul>                                                                                         | **Required**: <ul><li>Set at least one visualization: `pr_table`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                    | <ul><li>**No reference**: Fails if FPR is higher than the dummy model.</li><li>**With reference**: Fails if FPR differs by >20%.</li></ul>                                           |
| **FNR()**                   | <ul><li>Calculates False Negative Rate (FNR).</li><li>Metric result: TBC.</li></ul>                                                                                         | **Required**: <ul><li>Set at least one visualization: `pr_table`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                    | <ul><li>**No reference**: Fails if FNR is higher than the dummy model.</li><li>**With reference**: Fails if FNR differs by >20%.</li></ul>                                           |
| **LogLoss()**               | <ul><li>Calculates Log Loss.</li><li>Metric result: TBC.</li></ul>                                                                                                          | **Required**: <ul><li>Set at least one visualization: `pr_table`.</li></ul> **Optional**: <ul><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                                               | <ul><li>**No reference**: Fails if LogLoss is higher than the dummy model (equals 0.5 for a constant model).</li><li>**With reference**: Fails if LogLoss differs by >20%.</li></ul> |
| **RocAUC()**                | <ul><li>Calculates ROC AUC.</li><li>Can visualize PR curve or table.</li><li>Metric result: TBC.</li></ul>                                                                  | **Required**: <ul><li>Set at least one visualization: `pr_table`, `roc_curve`.</li></ul> **Optional**: <ul><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                                                  | <ul><li>**No reference**: Fails if ROC AUC is ≤ 0.5.</li><li>**With reference**: Fails if ROC AUC differs by >20%.</li></ul>                                                         |
| **Lift()**                  | <ul><li>Calculates lift.</li><li>Can visualize lift curve or table.</li><li>Metric result: TBC.</li></ul>                                                                   | **Required**: <ul><li>Set at least one visualization: `lift_table`, `lift_curve`.</li></ul> **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul>                                                                    | TBC                                                                                                                                                                                  |

Dummy metrics:

<Accordion title="Dummy model quality" defaultOpen={false}>
  Use these Metics to get the qulaity of a dummy model created on the same data (based on heuristics). You can compare your model quality to verify that it's better than random. Also serves as a baseline in automated testing.

  | Metric                           | Description                                                                                             | Parameters | Test Defaults |
  | -------------------------------- | ------------------------------------------------------------------------------------------------------- | ---------- | ------------- |
  | **ClassificationDummyQuality()** | <ul><li>Small Preset summarizing quality of a dummy model.</li><li>Metric result: all Metrics</li></ul> | N/A      | N/A         |
  | **DummyPrecision**               | <ul><li>Calculates precision for a dummy model.</li><li>Metric result: TBC.</li></ul>                   | N/A      | N/A           |
  | **DummyRecall**                  | <ul><li>Calculates recall for a dummy model.</li><li>Metric result: TBC.</li></ul>                      | N/A       | N/A           |
  | **DummyF1**                      | <ul><li>Calculates F1 Score for a dummy model.</li><li>Metric result: TBC.</li></ul>                    | N/A       | N/A           |
</Accordion>

### By label

Use when you have multiple classes and want to evaluate quality separately.

| Metric                             | Description                                                                                                             | Parameters                                                         | Test Defaults                                                                                                                                         |   |
| ---------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------- | - |
| **ClassificationQualityByLabel()** | <ul><li>Small Preset summarizing classification quality Metrics by label.</li><li>Metric result: all Metrics.</li></ul> | TBC.                                                               | As in individual Metrics.                                                                                                                             |   |
| **PrecisionByLabel()**             | <ul><li>Calculates precision by label in multiclass classification.</li><li>Metric result: TBC.</li></ul>               | **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: Fails if Precision is lower than the dummy model.</li><li>**With reference**: Fails if Precision differs by >20%.</li></ul> |   |
| **F1ByLabel()**                    | <ul><li>Calculates F1 Score by label in multiclass classification.</li><li>Metric result: TBC.</li></ul>                | **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: Fails if F1 is lower than the dummy model.</li><li>**With reference**: Fails if F1 differs by >20%.</li></ul>               |   |
| **RecallByLabel()**                | <ul><li>Calculates recall by label in multiclass classification.</li><li>Metric result: TBC.</li></ul>                  | **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: Fails if Recall is lower than the dummy model.</li><li>**With reference**: Fails if Recall differs by >20%.</li></ul>       |   |
| **RocAUCByLabel()**                | <ul><li>Calculates ROC AUC by label in multiclass classification.</li><li>Metric result: TBC.</li></ul>                 | **Optional**: <ul><li>`probas_threshold`</li><li>`top_k`</li><li>[Test conditions](/docs/library/tests)</li></ul> | <ul><li>**No reference**: Fails if ROC AUC is ≤ 0.5.</li><li>**With reference**: Fails if ROC AUC differs by >20%.</li></ul>                          |   |

## Regression

| Metric                     | Description               | Parameters | Test Default |
| -------------------------- | ------------------------- | ---------- | ------------ |
| **RegressionPreset**       | Preset. Includes metrics: |            |              |
| **RegressionQuality**      | Small Preset              |            |              |
| **RegressionDummyQuality** | Small Preset              |            |              |
| **MeanError**              |                           |            |              |
| **MAE**                    |                           |            |              |
| **RMSE**                   |                           |            |              |
| **MAPE**                   |                           |            |              |
| **R2Score**                |                           |            |              |
| **AbsMaxError**            |                           |            |              |
| **DummyMeanError**         |                           |            |              |
| **DummyMAE**               |                           |            |              |
| **DummyRMSE**              |                           |            |              |
| **DummyMAPE**              |                           |            |              |
| **DummyR2**                |                           |            |              |

## Ranking

| Metric                      | Description                                                                                                                                                                                                                                                                  | Parameters | Test Default |
| --------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- | ------------ |
| **RecsysPreset()**          | Preset. Includes: <ul><li>PrecisionTopK()</li><li>RecallTopK()</li><li>FBetaTopK()</li><li>MAPK()</li><li>NDCGK()</li><li>MRRK()</li><li>HitRateK()</li><li>Personalization()</li><li>PopularityBias()</li><li>Diversity()</li><li>Serendipity()</li><li>Novelty()</li></ul> |            |              |
| **RecallTopK()**            |                                                                                                                                                                                                                                                                              |            |              |
| **FBetaTopK()**             |                                                                                                                                                                                                                                                                              |            |              |
| **PrecisionTopK()**         |                                                                                                                                                                                                                                                                              |            |              |
| **MAPK()**                  |                                                                                                                                                                                                                                                                              |            |              |
| **NDCGK()**                 |                                                                                                                                                                                                                                                                              |            |              |
| **MRRK()**                  |                                                                                                                                                                                                                                                                              |            |              |
| **HitRateK()**              |                                                                                                                                                                                                                                                                              |            |              |
| **PersonalizationMetric()** |                                                                                                                                                                                                                                                                              |            |              |
| **PopularityBias()**        |                                                                                                                                                                                                                                                                              |            |              |
| **Diversity()**             |                                                                                                                                                                                                                                                                              |            |              |
| **Serendipity()**           |                                                                                                                                                                                                                                                                              |            |              |
| **Novelty()**               |                                                                                                                                                                                                                                                                              |            |              |