---
title: "Overview"
description: "Available evaluations and how to customize them."
noindex: "true"
mode: "wide"
---

Evidently offers 100+ customizable evals with visualizations. That's a core library feature. Before exploring, make sure you ran a simple eval (for [LLMs](../quickstart_llm), for [ML](../quickstart_ml)) and know the key components:
* **Descriptors** evaluate data row-by-row: return scores like text length or "PII detected" for each input.
* **Metrics** work at the dataset or column level. These are checks like accuracy, data drift, or column means. You also need Metrics to summarize row-level results.
* **Tests** let you add optional Pass/Fail checks on top of Metrics.
* **Reports** are how you group and visualize the evaluation results.

## Popular links

<CardGroup cols={4}>
  <Card title="All Descriptors" icon="table-list" href="all_descriptors">
    Reference table.
  </Card>

  <Card title="All Metrics" icon="chart-simple" href="all_metrics">
    Reference table.
  </Card>

  <Card title="LLM judges" icon="sparkles" href="customize_llm_judge">
    How to create.
  </Card>

  <Card title="Data Drift" icon="sparkles" href="explainer_data_drift">
    How to detect.
  </Card>
</CardGroup>
